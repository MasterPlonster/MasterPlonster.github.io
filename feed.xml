<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://www.eyalfisher.com/feed.xml" rel="self" type="application/atom+xml"/><link href="https://www.eyalfisher.com/" rel="alternate" type="text/html" hreflang="en"/><updated>2023-09-06T16:30:01+00:00</updated><id>https://www.eyalfisher.com/feed.xml</id><title type="html">blank</title><subtitle>AI Consultan, Enterpreneur, Ex-biostatistician. Building AI products for 12 years. </subtitle><entry><title type="html">Training Large Language Models with Skypilot</title><link href="https://www.eyalfisher.com/blog/2023/using-skypilot-to-train-langauge-models/" rel="alternate" type="text/html" title="Training Large Language Models with Skypilot"/><published>2023-08-04T12:57:00+00:00</published><updated>2023-08-04T12:57:00+00:00</updated><id>https://www.eyalfisher.com/blog/2023/using%20skypilot%20to%20train%20langauge%20models</id><content type="html" xml:base="https://www.eyalfisher.com/blog/2023/using-skypilot-to-train-langauge-models/"><![CDATA[<h2 id="about-skypilot">About SkyPilot</h2> <p>If you ever tried to finetune a large language model, you probably know that provisioning and preparing the hardware and environment can be a pain. GPU availability is limited, and you need to make sure you have the right CUDA version, the right drivers, and the right libraries.</p> <p>I’ve been using <a href="https://skypilot.readthedocs.io/en/latest/">SkyPilot</a> for a while now, and it made a big difference in my life. Initially it was just a convinience tool for me to quickly search for a GCP zone with A100 availability, but I quickly discovered that relying on it forces me to be much more organized and disciplined in organizing my training runs.</p> <p>Technically speaking, SkyPilot is an abstraction of Ray + Cloud provider SDK + some niceities, including folder syncing, a task queue and managment of spot instances. It’s free, open source, and easy to use. So let’s get started.</p> <h2 id="first-steps">First Steps</h2> <p>First, you need to <a href="https://skypilot.readthedocs.io/en/latest/getting-started/installation.html">install SkyPilot</a> and configure the CLIs for your favourite cloud providers.</p> <p>In you are using AWS:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>skypilot
pip <span class="nb">install </span>skypilot[aws]

pip <span class="nb">install </span>boto3
aws configure
</code></pre></div></div> <p>You also need to make sure that you’ve got the relevant quota set up for your account. With GCP there’s some API activation you need to do, and with AWS you need to request a quota increase. The documentation explains how to do that.</p> <p>Next, it’s time to configure your project. You can do that by creating a <code class="language-plaintext highlighter-rouge">skypilot.yaml</code> file in your project directory. Here’s an example:</p> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">resources</span><span class="pi">:</span>
  <span class="na">cloud</span><span class="pi">:</span> <span class="s">aws</span>
  <span class="na">accelerators</span><span class="pi">:</span> <span class="s">A100:4</span> <span class="c1"># Pick the kind and number of GPUs you want to use.</span>

<span class="c1"># Working directory (optional) containing the project codebase</span>
<span class="c1"># Its contents are synced to ~/sky_workdir/ on the cluster.</span>
<span class="na">workdir</span><span class="pi">:</span> <span class="s">.</span>

<span class="c1"># Invoked under the workdir (i.e., can use its files)</span>
<span class="c1"># This is where you set up your environment and install dependencies</span>
<span class="c1"># The machine will already have conda install so you can use that to set up your environment with the correct python version.</span>
<span class="na">setup</span><span class="pi">:</span> <span class="pi">|</span>
    <span class="s">conda create -n skypilot python=3.10</span>
    <span class="s">conda activate skypilot</span>

    <span class="s">pip install -r requirements.txt</span>

<span class="c1"># This is the main action, where you run your job.</span>
<span class="c1"># Invoked under the workdir (i.e., can use its files).</span>
<span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
    <span class="s">python train.py</span>
</code></pre></div></div> <p>Now creating a cluster and running the job is a simple as:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sky launch <span class="nt">-c</span> mycluster skypilot.yaml
</code></pre></div></div> <p>SkyPilot will also helpfully add the host to your ssh config, so you can easily ssh into it with <code class="language-plaintext highlighter-rouge">ssh mycluster</code>.</p> <p>To see your running clusters, it’s as simple as <code class="language-plaintext highlighter-rouge">sky status</code>, and you can terminate the cluster with <code class="language-plaintext highlighter-rouge">sky down mycluster</code>.</p> <h2 id="autostop">Autostop</h2> <p>As we all know, forgetting your training machine on can be expensive. SkyPilot has a nice feature called <code class="language-plaintext highlighter-rouge">autostop</code> that will automatically stop the machine after a certain amount of idle time. You can launch a task with autostop using the flag <code class="language-plaintext highlighter-rouge">-i</code> like this:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sky launch <span class="nt">-d</span> <span class="nt">-c</span> mycluster cluster.yaml <span class="nt">-i</span> 10 <span class="nt">--down</span>
</code></pre></div></div> <h2 id="saving-logs-and-artefacts">Saving Logs and Artefacts</h2> <p>Terminating a cluster when your task is done obviously means that everything stored on the machine is lost. The way I like to work is to save the Logs to Weights and Biases, and save the model checkpoints to either a bucket or HuggingFace Hub.</p> <p>If using a HuggingFace trainer this is as simple as addign <code class="language-plaintext highlighter-rouge">report_to=wand</code> and <code class="language-plaintext highlighter-rouge">push_to_hub=True</code> to the <code class="language-plaintext highlighter-rouge">TrainingArguments</code>. You do need to make sure you are logged in to both, or pass the relevant authentication tokens.</p> <p>While SkyPilot provides can use an env section in the skypilot.yaml pass environment variables, I like to store my template in github, which is not a safe place for secrets. Instead, I use a <code class="language-plaintext highlighter-rouge">.env</code> file in the project directory, which is synced by SkyPilot directly to the cluster, and then I can use it to set the environment variables like this:</p> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">resources</span><span class="pi">:</span>
  <span class="na">cloud</span><span class="pi">:</span> <span class="s">aws</span>
  <span class="na">accelerators</span><span class="pi">:</span> <span class="s">A100:4</span> <span class="c1"># Pick the kind and number of GPUs you want to use.</span>

<span class="c1"># Working directory (optional) containing the project codebase</span>
<span class="c1"># Its contents are synced to ~/sky_workdir/ on the cluster.</span>
<span class="na">workdir</span><span class="pi">:</span> <span class="s">.</span>

<span class="c1"># Invoked under the workdir (i.e., can use its files)</span>
<span class="c1"># This is where you set up your environment and install dependencies</span>
<span class="c1"># The machine will already have conda install so you can use that to set up your environment with the correct python version.</span>
<span class="na">setup</span><span class="pi">:</span> <span class="pi">|</span>
    <span class="s">conda create -n skypilot python=3.10</span>
    <span class="s">conda activate skypilot</span>

    <span class="s">pip install -r requirements.txt</span>

    <span class="s">export $(grep -v '^#' .env | xargs)</span>
    <span class="s">wandb login $WANB_TOKEN</span>

<span class="c1"># This is the main action, where you run your job.</span>
<span class="c1"># Invoked under the workdir (i.e., can use its files).</span>
<span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
    <span class="s">python train.py</span>
</code></pre></div></div> <h2 id="using-the-job-queue">Using The Job Queue</h2> <p>The job queue comes without any additional configuration, and is a great way to manage multiple jobs. After you spin up your cluster you can just send additional jobs with:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sky <span class="nb">exec </span>mycluster task.yaml <span class="nt">-d</span>
</code></pre></div></div> <p>Where <code class="language-plaintext highlighter-rouge">task.yaml</code> is a file with the same structure as <code class="language-plaintext highlighter-rouge">skypilot.yaml</code> containing a task configuration.</p>]]></content><author><name></name></author><category term="llm"/><category term="skypilot"/><category term="training"/><category term="llm"/><category term="tips"/><summary type="html"><![CDATA[a useful tool to help with hardware provisioing and environment setup for training large language models.]]></summary></entry></feed>